{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time each cell\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 536 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.nddata.utils import Cutout2D, PartialOverlapError, NoOverlapError\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import sigma_clipped_stats, sigma_clip\n",
    "from astropy.time import Time\n",
    "from astropy.utils.console import ProgressBar\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from copy import copy\n",
    "\n",
    "from piaa.utils import helpers\n",
    "from piaa.utils import images as img_utils\n",
    "from piaa import exoplanets\n",
    "from piaa.utils import pipeline\n",
    "from pocs.utils.images import fits as fits_utils\n",
    "\n",
    "palette = copy(plt.cm.inferno)\n",
    "palette.set_over('w', 1.0)\n",
    "palette.set_under('k', 1.0)\n",
    "palette.set_bad('g', 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.21 ms\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/var/panoptes/images/fields'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = 'PAN001/Wasp80/14d3bd/20180609T095151'\n",
    "# sequence = 'PAN001/Hd189733/14d3bd/20180614T093015'\n",
    "sequence = 'PAN001/Hd189733/14d3bd/20180807T071517'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_size = (14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download FITS files\n",
    "fits_blobs = helpers.get_observation_blobs(sequence)\n",
    "len(fits_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the FITS files from a bucket\n",
    "fits_files = list()\n",
    "if fits_blobs:\n",
    "    with tqdm(len(fits_blobs), 'Downloading FITS files'.ljust(25)) as bar:\n",
    "        for i, blob in enumerate(fits_blobs):\n",
    "            fits_fn = helpers.unpack_blob(blob, save_dir=data_dir)\n",
    "            fits_files.append(fits_fn)\n",
    "            bar.update(i)\n",
    "\n",
    "fits_files = fits_files\n",
    "num_frames = len(fits_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plate-solve all the images - safe to run again\n",
    "solved_files = list()\n",
    "with tqdm(\n",
    "        len(fits_files), \n",
    "        'Solving files'.ljust(25)) as bar:\n",
    "    for i, fn in enumerate(fits_files):\n",
    "        try:\n",
    "            fits_utils.get_solve_field(fn, timeout=90)\n",
    "            solved_files.append(fn)\n",
    "        except Exception:\n",
    "            print(\"Can't solve file {}\".format(fn))\n",
    "            continue\n",
    "\n",
    "solved_files = solved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(solved_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs = WCS(solved_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup point sources\n",
    "# You need to set the env variable for the password for TESS catalog DB (ask Wilfred)\n",
    "# os.environ['PGPASSWORD'] = 'sup3rs3cr3t'\n",
    "point_sources = pipeline.lookup_point_sources( \n",
    "    solved_files, \n",
    "    wcs=wcs, \n",
    "    force_new=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(point_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_sources.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcsecs = (point_sources.d2d.values * u.degree).to(u.arcsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(point_sources.x.values, arcsecs)\n",
    "plt.xlabel('Y position')\n",
    "plt.ylabel('Δ arcsec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcsec_bins = np.histogram(arcsecs, bins=np.linspace(0, 30, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_scale = 10.3\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.hist(arcsecs, bins=np.linspace(0, 25, 20))\n",
    "\n",
    "# ax2 = ax1.twiny()\n",
    "s2 = arcsec_bins[1] / pixel_scale\n",
    "\n",
    "ax1_ticks = ax1.get_xticks()\n",
    "# ax2_scale = ax1_ticks / pixel_scale\n",
    "\n",
    "# ax2.set_xlabel(\"Δ pixels\", fontsize=10)\n",
    "# ax2.set_xticks(ax2_scale)\n",
    "# ax2.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "# ax2.grid(color='r', linestyle='--', alpha=0.25, linewidth=2)\n",
    "\n",
    "ax1.set_xlabel(\"Δ arcsec\", fontsize=10)\n",
    "ax1.set_ylabel(\"Num of sources\")\n",
    "\n",
    "fig.suptitle('Tess Catalog Offset', y=1.05, fontsize=14)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_sources.snr.hist(bins=np.arange(0,100, 5))\n",
    "plt.ylabel('Num of sources')\n",
    "plt.title('SNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_sources.vmag.hist(bins=np.linspace(7, 15, 20))\n",
    "plt.ylabel('Num of sources')\n",
    "plt.title('Vmags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stamps\n",
    "stamps_fn = pipeline.create_stamp_slices(\n",
    "    sequence,\n",
    "    solved_files,\n",
    "    point_sources[point_sources.snr >= snr_limit],\n",
    "    stamp_size=stamp_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamps_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'PAN001_Wasp80_14d3bd_20180609T095151.hdf5'\n",
    "# stamps_fn = '/var/panoptes/psc/PAN001_Hd189733_14d3bd_20180614T093015.hdf5'\n",
    "# sequence = 'PAN001_Tres3_14d3bd_20180624T063045.hdf5'\n",
    "stamps_fn = '/var/panoptes/psc/' + sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamps = h5py.File(stamps_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picid = '243921117' # Wasp 80\n",
    "# picid = '256364928'\n",
    "# picid = '243952829'\n",
    "# picid = '248311256'\n",
    "# picid = '116264089' # Tres-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picid = list(stamps.keys())[np.random.randint(0, len(stamps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picid in stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_series = pipeline.find_similar_stars(\n",
    "    picid, \n",
    "    stamps,\n",
    "    out_fn='/var/panoptes/psc/similar_{}_{}.csv'.format(sequence.replace('/','_'), picid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_refs = 100\n",
    "camera_bias = 2048\n",
    "stamp_size = (14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_collection = np.array([pipeline.get_psc(str(idx), stamps) - camera_bias \n",
    "                           for idx in vary_series.index[:num_refs]])\n",
    "print(\"Stamp collection shape: {}\".format(stamp_collection.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_collection = np.array([pipeline.normalize(s) for s in stamp_collection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pipeline.get_ideal_full_coeffs(normalized_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = np.array(stamps[picid]['data']).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal = pipeline.get_ideal_full_psc(\n",
    "    stamp_collection, \n",
    "    coeffs[0]\n",
    ").reshape(num_frames, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = stamp_collection[0].reshape(num_frames, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = (target.sum(1) / ideal.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = helpers.animate_stamp(target.reshape(num_frames, stamp_size[0], stamp_size[1]))\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_times = np.array(stamps.attrs['image_times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_times = [Time(t0, format='mjd').to_datetime() for t0 in image_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc0 = pd.DataFrame(lc, index=image_times, columns=['rel_flux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc0.plot()\n",
    "plt.title('Relative flux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc0.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aperture_size = 4\n",
    "\n",
    "diff = list()\n",
    "for picid in ProgressBar(list(stamps.keys())):\n",
    "    try:\n",
    "        psc = pipeline.get_psc(str(picid), stamps) - camera_bias\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    if float(stamps[picid].attrs['vmag']) > 13:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        rgb_stamp_masks = helpers.get_rgb_masks(\n",
    "            psc[0].reshape(stamp_size[0], stamp_size[1]), \n",
    "            force_new=True\n",
    "        )\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    for frame_idx in range(psc.shape[0]):\n",
    "        d0 = psc[frame_idx].reshape(stamp_size[0], stamp_size[1])\n",
    "\n",
    "        star_pos_x = np.array(stamps[picid]['original_position'])[frame_idx][0]\n",
    "        star_pos_y = np.array(stamps[picid]['original_position'])[frame_idx][1]\n",
    "        slice0 = helpers.get_stamp_slice(star_pos_x, star_pos_y, stamp_size=stamp_size)\n",
    "\n",
    "        try:\n",
    "            y_pos, x_pos = np.argwhere(d0 == d0.max())[0]\n",
    "            aperture_position = (x_pos, y_pos)\n",
    "        except IndexError:\n",
    "            print(\"No star position: \", frame_idx, slice0, star_pos_x, star_pos_y)\n",
    "            continue\n",
    "\n",
    "        color_flux = dict()\n",
    "        for color, mask in zip('rgb', rgb_stamp_masks):\n",
    "\n",
    "            d1 = np.ma.array(d0, mask=~mask)\n",
    "\n",
    "            try:\n",
    "                d2 = Cutout2D(d1, aperture_position, aperture_size, mode='strict')\n",
    "            except (PartialOverlapError, NoOverlapError) as e:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            diff.append({\n",
    "                'picid': picid,                \n",
    "#                 'obstime': observation.stamps['image_times'][frame_idx],\n",
    "                'color': color,\n",
    "                'value': d2.data.sum(),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    lc = pd.DataFrame(diff).set_index('obstime')          \n",
    "\n",
    "    csv_file = '/var/panoptes/images/lc/{}_diff.csv'.format(sequence.replace('/', '_'))\n",
    "    print(\"Writing csv to {}\".format(csv_file))\n",
    "    lc.to_csv(csv_file)\n",
    "except Exception as e:\n",
    "    print(\"Problem creating CSV file: {}\".format(e))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = pd.read_csv('/var/panoptes/images/lc/{}_diff.csv'.format(sequence.replace('/', '_'))).set_index(['picid', 'obstime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = lc.groupby(by=['picid', 'color']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.to_csv('/var/panoptes/g_stats_{}_desc.csv'.format(sequence.replace('/', '_')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picid_list = lc.picid.unique()\n",
    "\n",
    "stats = list()\n",
    "for picid in tqdm_notebook(picid_list):\n",
    "    rows = lc.picid == picid\n",
    "    color = lc.color == 'g'\n",
    "\n",
    "    l0 = lc[rows & color]\n",
    "    \n",
    "    count_mean, count_median, count_std = sigma_clipped_stats(l0.value)\n",
    "    \n",
    "    mag = -2.5 * np.log10(l0.value / 120)\n",
    "\n",
    "    mag_mean, mag_median, mag_std = sigma_clipped_stats(mag)\n",
    "    \n",
    "#     std = (l0.value - l0.value.mean()).std()\n",
    "#     avg_std = (std / l0.value).mean()\n",
    "\n",
    "    # Get the vmag\n",
    "    vmag = observation.stamps[str(picid)].attrs['vmag']\n",
    "    \n",
    "    stats.append([vmag, count_mean, count_median, count_std, mag_mean, mag_median, mag_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_stats = pd.DataFrame(noise, columns=['vmag','count_mean', 'count_median', 'count_std', 'mag_mean', 'mag_median', 'mag_std'], index=picid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_stats.to_csv('/var/panoptes/g_stats_{}.csv'.format(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = g_stats.vmag\n",
    "stds = g_stats.mag_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(mags, stds, alpha=0.25)\n",
    "plt.xlim([6,14])\n",
    "plt.ylim([0, .2])\n",
    "plt.xlabel('V mag')\n",
    "plt.ylabel('Standard dev. (mag.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.groupby(by='picid').vmag.hist(bins=np.arange(6,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.vmag.hist(bins=np.arange(6,17))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
