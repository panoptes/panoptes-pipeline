{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find similar stars\n",
    "\n",
    "Because a simple differential photometry doesn't work well we need to find a suitable set of reference stars that undergo the same changes (e.g. airmass, cloud cover, etc) as our target star.\n",
    "\n",
    "Ultimately we are concerned about how the flux of our target changes with respect to a suitable set of reference stars and therefore we need to be careful **not** to use flux as a selection parameter for determining the \"best\" reference stars. That is, we **do not** want to choose reference stars that undergo a reduction of flux in the middle of the observation as this will hide the transit signal in our target.\n",
    "\n",
    "We can marginalize across the flux by normalizing each stamp to the total flux in the stamp (see [Normalize](Algorithm.ipynb#normalize) in algorithm description). By doing so we are effectively looking at the shape of the star as it appears on the RGB pixel pattern. This morphology will change slightly from frame to frame so we want to look for reference stars that change similarly to our target star with respect to this morphology.\n",
    "\n",
    "By taking the summed squared difference (SSD) between each pixel of the normalized target and reference star we can get a single metric that defines how well the reference star matches the target. Because the SSD is looking at the difference between the target and a reference, a lower metric value for the refernce indicates a better match with the target. The target stamp compared with itself would yield a value of zero.\n",
    "\n",
    "We perform the SSD for each frame in the observation and take the sum of all the SSDs for each source as the final metric score to compare against our target. Again, lower scores mean that the reference is more \"similar\" in a morphological sense: it's shape on the RGB pattern changes similar to that of the target. See [Find Reference Stars](Algorithm.ipynb#find_reference) for details and mathematical description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the ranking for comparison stars\n",
    "\n",
    "For each source that was identified above we want to find the most \"similar\" stars by ranking them according to how the shape of their PSF differs from that of the target. This is done for each frame and the sum across all frames determines the \"similarity\", with smaller final sums indicating stars that are similar to the target. The target ranked against itself would yield a value of zero.\n",
    "\n",
    "By the numbers, this is doing the sum of the summed squared difference (SSD) for each pixel in the stamp for each frame. Importantly, it is doing this comparision on the normalized version of each stamp. The stamp is normalized according to the total sum of the stamp. See [Step 1](Algorithm.ipynb#normalize) below for the Normalization and [Step 2](Algorithm.ipynb#find_references) for the sum of the SSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 6\n",
    "\n",
    "vary = defaultdict(float)\n",
    "\n",
    "# For each frame in the observation\n",
    "for date_obs, row in tqdm_notebook(target_table.iterrows(), total=len(target_table)):\n",
    "\n",
    "    frame_data = fits.getdata(os.path.join(base_dir, row.file))\n",
    "\n",
    "    stamp_slice = helpers.get_stamp_slice(row.x, row.y, stamp_size=(size, size), ignore_superpixel=True)\n",
    "    target_data = frame_data[stamp_slice]\n",
    "    \n",
    "    # Normalize stamp\n",
    "    normalized_target_data = target_data / target_data.sum()\n",
    "    \n",
    "    # For each identified reference source\n",
    "    for source_id in tqdm_notebook(all_source_ids, leave=False):\n",
    "#     for source_id in all_source_ids:\n",
    "        try:\n",
    "            # Note that the `name` is the date-obs\n",
    "            reference_row = source_table.loc[source_id, row.name]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        reference_slice = helpers.get_stamp_slice(reference_row.x, reference_row.y, stamp_size=(size, size), ignore_superpixel=True)\n",
    "        reference_data = frame_data[reference_slice]\n",
    "        \n",
    "        normalized_reference_data = reference_data / reference_data.sum()\n",
    "        v_score = ((normalized_target_data - normalized_reference_data)**2).sum()\n",
    "        vary[source_id] += v_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_series = pd.Series(vary).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_series.to_csv(os.path.join(base_dir, 'vary-{}-{}.csv'.format(unit_id, picid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
